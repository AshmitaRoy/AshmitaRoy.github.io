---
title: "CMSC320: 0101: Final Project"
output: html_document
---
<span style="color:darkgreen"> </span>
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
<p style="font-family: times, serif; font-size:30pt; font-style:bold"> <span style="color:green"> Houses in California </p>

####<span style="color:navy">By Ashmita Roy </span>

<p style="font-family: times, serif; font-size:25pt; font-style:bold"> <span style="color:lightgreen"> Introduction: </span> </p>

<p style="font-family: times, serif; font-size:14pt; font-style:bold"> <span style="color:Navy"> 
Who doesn't dream of owning a house in the Bay Area?! California is a dream for homeowners and this dream shows no signs of dying down. However, this poster (showing land companies putting out advertisements to attract homeowners to California) dated 12 October 1876 tells us that it was not always so! </p> 

<div style="width:200px; height:400px; float: right">
![][id6] 
</div>

We will use the Housing Data for California dataset (containing information from the 1990 California census) to investigate this. Initially this tutorial walks you through the process of cleaning the available data, some visualisation of the data for exploratory analysis and then follow it up with some models to predict the value of a house in a particular block/location of California.


#####This tutorial walks you through the process of the Data Science Pipeline:  

* Gathering, parsing and cleaning available data: on Housing Blocks in California from 1990
* Exploratory data analysis and data visualisation : See the dataset in a visual form with plots and get an image of what the values are typically.
* Statistical and Machine Learning : Make predictions about attributes of the dataset using other attributes and then check how accurate our predictions , using a model were.


<div style="width:700px; height:300px; float: middle">
![][id]
</div>

###<span style="color:green"> Data Exploration </span>

<style>
div.blue pre { background-color:#fff68f; }
div.blue pre.r { background-color:#afeeee; }
</style>


###Pre-requisites:
* R or RStudio

* Packages in R are third-party add-ons that allow a multitude of actions. To install a package
    : Open RStudio or R and type the following into the console:<span style="color:green"install.packages("package_name")</span>

* Install the following packages: 
    + tidyverse  
    + reshape2  
    + boot  
    + randomForest  
    + coefplot
    
<div class = "blue">
```{r, message=FALSE}

#loading the packages we've installed
library(tidyverse)
library(reshape2)
```
</div>

##Data Ingestion, Cleaning
With any task, the quality of the output depends on the quality of the inputs. Thus, gathering, cleaning and preparing data in any project is of immense importance. 

##Initialisation:

###Step 1

* GATHER DATA

Download the dataset( available as a CSV file named housing.csv ) from [https://www.kaggle.com/camnugent/california-housing-prices/downloads/california-housing-prices.zip/1] [id1]

* INGEST AND PARSE DATA  

The readr R package, included in our tidyverse package allows us to use read_csv to read a dataset in a CSV(comma-separated-value) file.  
<span style="color:tomato"> [ Ensure that you have downloaded your dataset into your current working directory.] </span> .  
You can READ more about the readr package [here] [id2]  

<div class = "blue">
```{r}
#to read the CSV file, located in the current working directory
housing = read.csv('housing.csv')

#to display the first few records from all the columns, a glance at the data itself
head(housing)

```
</div>

This tells us that the dataset describes houses and their occupants.  
It is evident that each row is denoting a certain block of households.  
By now, we have taken a peek at the data.  
Now, we attempt to get a gist of the dataset we are dealing with.

<div class = "blue">
```{r}
#summarized description of the attributes
summary(housing)


#to get an idea about all the columns in the dataset, we check the Column Names
colnames(housing)
```
</div>

###:<span style="color:green"Step 2</span>

##__Data Exploration and Visualization__

Exploring data visually is a considerably important initial step. Visualization gives us the chance to pinpoint structure, similarities, potential relationships and aberrations in the dataset. Quite commonly, no further formal analysis is required as visual data exploration aids the user fully.  
Else, it acts as a vital stepping stone to future formal analyses.

Now an attempt can be made to transform this dataset into a graphical form, so it is easy to grasp as a visual concept.  
We do this using ggplot (which was included in our tidyverse package) to create histograms for each attribute.
This cheatsheet can help while using ggplot [https://www.rstudio.com/wp-content/uploads/2015/03/ggplot2-cheatsheet.pdf] [id3]

###2.1 Creating plots to visualise the dataset:  


###Histogram showing the median house value for households within a block (measured in US Dollars)
<div class = "blue">

```{r, message=FALSE}
#adding colour to the histogram
barfill="#87CEEB"
baroutline="#00ced1"

#Creating a histogram where median_house_value is plotted along the X axis
hist <- ggplot(housing, mapping=aes(x=median_house_value)) + geom_histogram( colour= baroutline, fill=barfill, alpha=1 ) + scale_x_continuous(name = "Median House Value") + scale_y_continuous(name = "Count")
hist
```
</div>

__NOTE:__     

* We see that the median_house_value ie the value of the house seems to be capped at a certain maximum value, which we must remember to allow for in our analysis.  
* Various colours can be added to plots to add dimension and interactivity.  
Obtain the pertinent colour codes from [https://www.color-hex.com/] [id4]  
* In the next few plots, we will use a __gradient of colours__ to enhance the histogram's visual impact.  
You can learn more about this [here] [id5].  

###Histogram showing the total number of rooms
<div class = "blue">

```{r, message=FALSE}

#Creating a histogram where total_rooms is plotted along the X axis
hist <- ggplot(housing, mapping=aes(x=total_rooms, fill=..count..)) + geom_histogram( alpha=0.9 ) + scale_x_continuous(name = "Total Number of Rooms") + scale_y_continuous(name = "Count") +scale_fill_gradient("Count", low = "yellow", high = "#00ced1")
hist
```
</div>

####__NOTE__:
This dataset provides us with total number of rooms for a housing block, which, intuitively might not seem very useful, given that our intention here is to predict the value of a house, we will look into how we might convert this into a value for a housing unit as opposed to an entire block.  

###Histogram showing the distribution of median income for households within a block of houses (measured in tens of thousands of US Dollars) 
<div class = "blue">

```{r, message=FALSE}

#Creating a histogram where median_income is plotted along the X axis
hist <- ggplot(housing, mapping=aes(x=median_income, fill=..count..)) + geom_histogram( alpha=0.9 ) + scale_x_continuous(name = "Median Income of Housing ") + scale_y_continuous(name = "Count") +scale_fill_gradient("Count", low = "#ccff00", high = "lightblue")
hist
```
</div>


###Histogram showing the distribution of age across housings
<div class = "blue">

```{r, message=FALSE}

#Creating a histogram where housing_median_age is plotted along the X axis
hist <- ggplot(housing, mapping=aes(x=housing_median_age, fill=..count..)) + geom_histogram( alpha=0.9 ) + scale_x_continuous(name = "Median Age of Housing ") + scale_y_continuous(name = "Count") +scale_fill_gradient("Count", low = "red", high = "navy")
hist
```
</div>

###Histogram showing the total number of bedrooms
<div class = "blue">

```{r, message=FALSE}
#adding colour to the histogram

#Creating a histogram where total_bedrooms is plotted along the X axis
hist <- ggplot(housing, mapping=aes(x=total_bedrooms, fill=..count..)) + geom_histogram( alpha=0.9 ) + scale_x_continuous(name = "Total Number of Bedrooms") + scale_y_continuous(name = "Count") +scale_fill_gradient("Count", low = "orange", high = "purple")
hist
```
</div>

####__NOTE__
The warning we received after plotting the histogram for the __total_bedrooms__ attribute :  
(`Removed 207 rows containing non-finite values (stat_bin) `)   
tells us that missing values exist, which we will impute in our next step.

###Histogram showing the distribution of population across housing blocks
<div class = "blue">

```{r, message=FALSE}

#Creating a histogram where population is plotted along the X axis
hist <- ggplot(housing, mapping=aes(x=population, fill=..count..)) + geom_histogram( alpha=0.9 ) + scale_x_continuous(name = "Population Count of Housing ") + scale_y_continuous(name = "Count") +scale_fill_gradient("Count", low = "#ff1493", high = "gold1")
hist
```
</div>

###Histogram showing the distribution of number of households across housing blocks
<div class = "blue">

```{r, message=FALSE}

#Creating a histogram where households is plotted along the X axis
hist <- ggplot(housing, mapping=aes(x=households, fill=..count..)) + geom_histogram( alpha=0.9 ) + scale_x_continuous(name = "Number of Households in a Housing ") + scale_y_continuous(name = "Count") +scale_fill_gradient("Count", low = "tomato", high = "blue")
hist
```
</div>

####The above seemingly random attempts at visualising our dataset may not seem intuitive or helpful at this point, but they offer us multiple takeaways:

It is necessary for us to resolve the following issues:  

* Issue 1. Impute missing values like N/A that exist in the dataset.
* Issue 2. The ranges for the variables vary hugely, thus we require to standardize the scale of the data when we use any non-tree based methods 
* Issue 3. It is noticeable that the columns involve the total number of rooms, bedrooms which we woud prefer to convert to a mean value for that housing block. 
* Issue 4: Categorical columns need to be converted into a type that can be handled and manipulated more easily.


### Step 2.2 Cleaning the data based on insights from the visualisations carried out:

####Resolving Issue 1: 
Here we fill in the missing values with the median of the column for total_bedrooms. For more help on imputing missing/erroneous values, see [here] [id7].
<div class = "blue">

```{r, message=FALSE}
summary(housing)
housing$total_bedrooms[is.na(housing$total_bedrooms)] = median(housing$total_bedrooms , na.rm = TRUE)
housing_imputed <- housing
```
</div>

####Resolving Issue 3:
We also noticed that the columns for total number of bedrooms and total number of rooms would be better off converted into a central statistic like a mean or a median value. As the mean can be easily calculated, we use it here.

<div class = "blue">

```{r, message=FALSE}

#adding a column 'mean_bedrooms' 
housing$mean_bedrooms = housing$total_bedrooms/housing$households

#adding a column 'mean_rooms' 
housing$mean_rooms = housing$total_rooms/housing$households

#to drop the total_bedrooms and total_rooms columns
housing <- subset(housing, select = -c(total_bedrooms, total_rooms))

#we check the new columns now
head(housing)

```
</div>

####Resolving Issue 4:
Now we will tackle the issue of the categorical column, __ocean_proximity__ and convert it into a value we can utilise better.

<div class = "blue">
```{r}
#first we check what the possible values in the column are
levels(housing$ocean_proximity)
```
</div>

We will create a new categorical table so that its columns correspond to the categorical levels of the ocean_proximity column.   

<div class = "blue">
```{r}
list_types = unique(housing$ocean_proximity)

#split the types of ocean_proximity off
oceanprox = data.frame(ocean_proximity = housing$ocean_proximity)
for(c in list_types)
{
    oceanprox[,c] = rep(0, times= nrow(oceanprox))
}
for(i in 1:length(oceanprox$ocean_proximity))
{
    c = as.character(oceanprox$ocean_proximity[i])
    oceanprox[,c][i] = 1
}

# drop the ocean_proximity column now from this categorical table
oceanprox <- subset(oceanprox, select = -c(ocean_proximity))

#rename columns to omit spaces for ease of usage later on
colnames(oceanprox)[colnames(oceanprox)=="NEAR BAY"] <- "NEAR_BAY"
colnames(oceanprox)[colnames(oceanprox)=="NEAR OCEAN"] <- "NEAR_OCEAN"
colnames(oceanprox)[colnames(oceanprox)=="<1H OCEAN"] <- "OCEAN_1H"
#We don't need to change the INLAND and ISLAND columns as they are unspaced already

#We impute the table for missing values
oceanprox$OCEAN_1H[is.na(oceanprox$OCEAN_1H)] = median(oceanprox$OCEAN_1H , na.rm = TRUE)

#we check the new columns now
head(oceanprox)
```
</div>

####Resolving Issue 2: 

Now we drop the __ocean_proximity__ and __median_house_value__ columns from our original dataset.  
Then we scale our original dataset. You can read more about the scale function in the [official R documentation, here] [id8]

<div class = "blue">
```{r}


# drop the ocean_proximity column and median_house_value 
housing_new <- subset(housing, select = -c(ocean_proximity, median_house_value))

#now we scale this dataset
housing_scaled <- scale(housing_new)

#we take a look at our new data
head(housing_scaled)

```
</div>

### Step 2.3

####Finally, we merge the categorical table, with the values of ocean_proximity and the new cleaned, scaled housing table. We also add the median house value obtained from our imputed housing table, as a column.  


Thus the resulting dataset from this step is a table containing all the original attributes, with the following differences:  
* the proximity ot the ocean has now been converted from a categorical to numeric attribute  
* the median housing value has been imputed to remove all N/A values and substituted with the median of that column

<div class = "blue">
```{r}
housing_final = cbind(oceanprox, housing_scaled, median_house_value=housing_imputed$median_house_value)
head(housing_final)
```
</div>

####__NOTE__
After modifying our ocean_proximity column into 5 columns, we can visualise this to get a better idea about this attribute of our dataset.

####Time based value plot showing the proximity to the ocean of a housing unit across housing blocks
You can learn more about this handy function [here][id10]
<div class = "blue">

```{r, message=FALSE}
plot.ts(oceanprox)
```

###Step 3
In our simple linear regression model, the goal is to analyse a relationship between variables, which we for simplicity, assume is given by a linear function.

__Create test set of data: __

We can begin testing some predictive models to predict the median value of the house using a few attributes as predictors : 

<div class= "blue">
```{r}
#We set a random seed value
set.seed(1111)

n=nrow(housing_final)
sample = sample.int(n, size = floor(1*nrow(housing_final)), replace = F)

#The training will be done based on the samples
housing_training = housing_final[sample, ] 

#The test will be done based on everything but the samples
housing_test  = housing_final[-sample, ] 

#a glimpse at the training dataset
head(housing_training)

```
</div>

####Now we are checking if the median house value depends on the following factors:  
* median income of that block  
* the mean number of bedrooms  
* the mean number of rooms  
* the population count of the block
* longitude  
* latitude  
* median age distribution of the block

Thus we are checking how the median value of the house depends on the other relevant attributes present in our dataset. I don't include the proximity to the ocean (in terms of the 5 categories of values), as that will be covered in a later subsection as an extra sidenote.

<div class = "blue">
```{r, message=FALSE}
#This package provides extensive facilities for bootstrapping and related resampling methods
library('boot')

house = glm(median_house_value~median_income+mean_rooms+mean_bedrooms+population+latitude+longitude+housing_median_age, data=housing_final)

error = cv.glm(housing_final , house, K=8)
error$delta
```

```{r}
rmse = sqrt(error$delta)[1]
rmse

#To check what is callable
names(house)

#Now we check the linear coefficients of the equation
house$coefficients

```
</div>


####Interpreting the above results:
We can see that the coefficient for median_income outweighs the other predictors greatly, ie it is the biggest driving factor in determining the median value of a house in a certain block.
We can also see how some of the attributes hardly contribute to the median housing value, thus later we can treat them as negligibly significant.

###Final Insights:
After scaling our inputs we can see that out of the factors we checked, the major effect on the median housing value was by median_income ie the median income of the housing block. However, this is a hasty judgement and other questions must be delved into before declaring any results.

__NOTE: My RF model stopped working randomly so I was forced to use only a simple linear models, however, a RandomForest can help with accurate predictions and better test and training data.__


####__EXTRA IDEAS:__

* You can build a coefficient plot using the package __coefplot__  
* You can have more fun with this package and learn about it [here][id9]  
* For example, to show the relationship between the median house value and a few of the other attributes.  
<div class= "blue">
```{r, message=FALSE}
library(coefplot)

data(housing)
model1 <- lm(housing$median_house_value~median_income+mean_rooms+mean_bedrooms+population, data=housing)
coefplot(model1)
```

  </div>
  
* One can proceed similarly with the idea of predicting which kind of proximity to the ocean is most desirable. Here of course, we are limited by the fact that desirability and popularity of the housing location is denoted by the price/ median value of the unit. 

<div class="blue">
```{r, message=FALSE}

house_ocean= glm(housing_final$median_house_value~housing_final$INLAND+housing_final$ISLAND+housing_final$NEAR_BAY+housing_final$NEAR_OCEAN+housing_final$OCEAN_1H)
error = cv.glm(housing_final , house_ocean, K=5)
error$delta
rmse = sqrt(error$delta)[1]
rmse

#Now we check the linear coefficients of the equation
house_ocean$coefficients

```
</div>

####Interpreting the above results:
We can see that the coefficient for ISLAND outweighs the other predictors greatly, ie it is the biggest driving factor in determining the median value of a house in a certain block.


###Acknowledgements:  
This data was initially featured in the following paper: Pace, R. Kelley, and Ronald Barry. "Sparse spatial autoregressions." Statistics & Probability Letters 33.3 (1997): 291-297.

###References:  
* Housing Dataset from Kaggle: https://www.kaggle.com/camnugent/california-housing-prices/downloads/california-housing-prices.zip/1
* R Documentation: https://www.rdocumentation.org/ 
* Extra help for R: https://cran.r-project.org/
* Color codes from https://www.color-hex.com/
* CMSC320 Lecture Notes: http://www.hcbravo.org/IntroDataSci/bookdown-notes/   
* California Land Popularity, Image: https://www.quora.com/Was-California-always-a-popular-state  
* Missing Data in R:https://medium.com/coinmonks/dealing-with-missing-data-using-r-3ae428da2d17 
* Using ggplot: http://r-statistics.co/Top50-Ggplot2-Visualizations-MasterList-R-Code.html


[id]: dsprocess.png 
[id1]: https://www.kaggle.com/camnugent/california-housing-prices/downloads/california-housing-prices.zip/1
[id2]: https://cran.r-project.org/web/packages/readr/index.html
[id3]: https://www.rstudio.com/wp-content/uploads/2015/03/ggplot2-cheatsheet.pdf
[id4]: https://www.color-hex.com/
[id5]: http://t-redactyl.io/blog/2016/02/creating-plots-in-r-using-ggplot2-part-7-histograms.html
[id6]: cal.jpg
[id7]: https://medium.com/coinmonks/dealing-with-missing-data-using-r-3ae428da2d17
[id8]: https://www.rdocumentation.org/packages/base/versions/3.6.0/topics/scale
[id9]: https://cran.r-project.org/web/packages/coefplot/coefplot.pdf 
[id10]: https://www.rdocumentation.org/packages/stats/versions/3.6.0/topics/plot.ts